# Pong AI

## Подготовка

Трениировать наборами
Будет забавно скрещивать 2х лучших игроков с разных сторон, если будет нужно

Чтобы с обеих сторон мог играть ИИ - на нейроны подавать значение по Х относительно стороны

поставить стену, которая отбивает в рандомном направлении

## Следование за направлением

Сначала все веса были положительными и модель быстро начинала следовать только за направлением, что было лучше чем ничего, но давало ошибки

Сопротивление, но дрожание - добавление ступенчатой функции активации для выходного нейрона (потому что по сути бинарный выход)

## Смещения и функция активации на выходной нейрон

- смещение -+
- порог на выходной с мутацией

есть стремеление наверх (после двух попыток) - хочется исправить

Смещения хотелось для ощущения середины доски. Так как это входило в понятие моей желаемой стратегии
Я передаю Верхнюю точку Игрока - поэтому смещения нужны
Кроме того, входы не нормализованны по влиянию, например ballY должен быть и отрицательным относительно середины

Со смещениями тренировать становится сложнее, популяции должны быть больше. Сделал рендер только первый 50

проблемы со сбрасываением

## 2 "скриншота"

приходил друг + кажется может решить проблемы со сбрасываением
Решил сделать это перед большим отбором

Сделал, довольно бытро обучаются, в 5 поколении уже играли почти идеально
Как и ожидалось ведут себя лучше сети у которых есть нейроны в скрытом слое которые получают разницу старого и нового положения за счет разнознаковых весов
НО! стратегия мне не нравится - это идельное следование за Y шарика

## Почкование и плавное изменение среды

Пытался брать плату за движения (любое, даже если уперся в стену), но тогда начинали выигрывать в основном те которые не ходят ниже середины.
Выход вижу в скрещивании (чтобы преодолеть локальные минимумы), добавлении новых нейронов (чтобы появились те которые дополнительно блокируют движение) или даже слоя (чтобы возрасла степень абстракции, и сетка стала умнее )
потому что по сути я хочу чтобы он научился предсказывать куда прилетит мяч,

Но сначала мне хотелось убедиться что я попробовал все с данной конфигурацией, Вероятно я слишком резко вносил изменения и ИИ не успевал адаптироваться. Но самому лень было медленно двигаться, поэтому я решил создать условия с плавным изменением среды и авто размножением.

- попробовал взять лидера (5 поколение) и с move cost -5 начать из него растить с усложнением в 1 для каждого след поколения

  - популяция разраслась до 8 поколения (начиная с 5), что увеличило цену за перемещения до 8 едениц.
  - было несколько потомств от 6 и 7 поколения, но развится лучше популяции не удалось

- Все вымерли. Вероятно увеличение цены за любое перемещение приводит к тому что в какой то момент становится невозможно набрать очки.

  - надо начать штрафовать за лищние перемещения, больше чем доска, но дороже (и разрешить упирать стену??? )
  - пробовал прирост -10 за лишние перемещения - быстро развились до 10-11 поколения, но с возросшей ценой до 60 за лишние перемензения все быстро умерли
  - вероятно среда менялась слишом быстро, попробую прирост -5

- если вымрут все надо попробовать рандом с 0 начальной ценой за перемещения

- вымрала вся популяция - может надо позволить пушить стену?

Откладывание размножения при превышении максимального количества особей позволит накопить полезные мутации и обработать их позже, при освобождении места в популяции.
Алгоритм сначала обрабатывает самых молодых особей, уже накопивших потенциал к размножению чтобы быстрее двигаться в сторону повышения агрессивности среды. Тем не менее, более взрослые особи способные сохранить свой потенциал к размножению в более агрессивной среде смогут реализовать его если потомки не смогли.
Это обеспечит и плавность изменение среды, и позволит ограничить количество особей и сохранит полезные мутации на будущее.
Так же установим минимальный угол отскок от стенки, чтобы сделать ее более сложным противником, чтобы исключить тех, кому просто повезло с углом отскок от нее.

Вызывает привычку отбивать серединой чтобы не катится за своим же шариком - но с противником, а не со стенкой, это не лучшее поведение! Но думаю можно будет это решить потом в спарринге.

Но и порог размножения должен быть непростым, чтобы отсекать случайное везение некоторых сиблингов. Забавно как взращивая одно свойство можно получить другое.
Уже с 8 поколения заметно как не ходят до края , если не нужно,

Если какая то особь мне понравилась-я все еще могу принудительно ее размножить

Изначальный штраф должен быть не слишком строгим - достаточным для выживания и размножения. Больше мутаций-больше возможностей.

Уперлись в отбивателей серединой. Дальше не движется

Начал с нулевого поколения. Появляются те которые могут не ходить в одну из сторон, но обязательно ходят во вторую. Но они и начинают пропускать, если не следуют точно за У. Как будто просто теряют чувствительнось, а не вырабатывают новую стратегию.
Может правда не хватает гейронов

среда
Очевидно что самый лучший будет не обязательно в последнем поколении, поэтому добавим кнопки watch & watch generation
Первое поколение делаем размером с популяцию
чтобы ускроить проверку старичков, которые успели накопить огромную сумму очков - будем их рестарить (но не последние 3 поколения)
Делать рестарт автоматически если уперлись в лимит популяции? Хотя бы как то для старых поколений (не предыдущее)

## добавление нейроной, слоев

Передавать 2 икса тоже. Только так как будто всегда от игрока плюс. Тупо что один нейрон всегда будет иметь одно и то же значение, может не надо??

Я хотел чтобы он предугадывал на стадии приема мяча и возвращался с середину на стадии ожидания удара противника - это та стратегия которую бы я сам выбрал чтобы играть.

Первый слой анализирует входные данные

Два из них Чувствуют скорость по разгице разнице координат по Х и У,
2 отслеживают позицию игрока по отношению к шарику по Х и У

Остальные 3 нейрона должны быть на отдельном слое чтобы использовать полученныеданные и принимать рещения. Условно два анализируют скорость и положение по осям. И один тормозящий который аналищирует из все

Возможно и полносвязность не нужна на первом слое и для двух нейронов на втором. Но оставим пока и понаблюдаем как будут выглядеть веса у успешных особей.

Значения получаются небольшими для конечного слоя, можно применить пороговую функцию активации ко всем нейронам

После нескольких попыток когда вся популяция вымирала я смог определить насколько плавно должна меняться среда чтобы вырастить успешных игроков из полного рандома.

Притычка отбивать центром чтобы меньше двигаться осталась - надо ввести премию за отбивание ближе к краю и штраф за центр. Буду всегда давать четверть ставки стимуляции умноженное на угол / макс угол

Со временем влияние цены за движения все равно начинает перевешивать влияние премии за игру краями, поэтому надо в премию игры краями как то включить штраф ща движения

У 11с watch есть дрожание - Чтобы избавить от дрожаний ввести небольшую плату за все движения. Появилась привычка стоять в углах, потому что приперея стенку можно избежать платы за дродание. Поэтому начнем списывать плату даже просто за попытку перемещения

Можно заметить как в середину начинают стремиться при увеличении платы за перемещения.

Деление можно отключить через параметр population , выбор из всех выживших можно спустить через рестарт

Пробы

- добавил еще 2 нейрона на ощущение середины, макс начальное смещение поднял до 0.25
- сделал смещения изначально 0 с коэф макс мутацией =1 . 2 нейрона оставил
- убрал смещения, убрал 2 нейрона, сделал спуск bounce мендленее
- вернул смещение, сделал его 0.5 макс инит, вернул 2 нейрона, сделал спуск по fail и move мендленнее

итог: среда должгна меняться очень плавно

Чтобы избежать дрожания будем считать всякую смену направления как лищний ход + Штрафовать за все изменения движения - за старт и за стоп получается брать тоже. За “нерешительность”

## TODO

- ai - ai + выбор контроллера
- передавать данные оппонента чтобы хитрее играл
- скрещивание на 2?
  Считать на вилеокарте
  Оставить только рендер одного сета?
